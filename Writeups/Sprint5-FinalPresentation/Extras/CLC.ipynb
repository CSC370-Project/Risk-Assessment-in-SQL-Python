{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course-level competencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course develops three major competencies that map onto three industry roles:\n",
    "\n",
    "- Data Analyst (somebody who extracts insights from data)\n",
    "- Data Architect (somebody who designs databases)\n",
    "- Back-end Engineer (somebody who develops non-user-facing code on software stacks)\n",
    "\n",
    "The pages in this pseudo-lesson describe the competency levels related to each of these roles, as relates to the content in this course. The course is designed to progress through these levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting insights into coherent data visualisations from a relational database using complex, expressive SQL code that completes within a reasonable amount of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 1:** Writes SQL code to generate desired effects on a relational database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anticipates the result of SQL queries executed against relation instances\n",
    "- Expresses declarative query intent in terms of relational operators\n",
    "- Extracts data from relations with precise selection predicates and attribute projection\n",
    "- Combines data from tables with appropriately chosen JOIN operations\n",
    "- Modifies data in relations in bulk with set-theoretic SQL DML queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Level 2:** Massages data into visualisation-ready layouts by slicing, dicing, pivoting, and rolling it up it directly in SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Expresses complex logic as single SQL queries using aggregation and sub-queries\n",
    "- Understands how functional dependencies and referential integrity affect the semantics of queries\n",
    "- Describes the logical ordering of operators in complex queries that involve nested logic\n",
    "- Plans out how to transform data from relations into a desired output layout as in standard OLAP/ETL operators\n",
    "- Prefers embedding complex logic into RDBMS over handling it in application-layer code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 3:** Uses a variety of SQL constructs and indexes to produce readable, efficient, idiomatic queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avoids sub-queries when possible.\n",
    "- Identifies which attributes should be indexed in order to accelerate a query.\n",
    "- Embraces declarative aspect of SQL to write concise code and avoids iteration logic whenever possible.\n",
    "- Styles code in a manner consistent with the broader SQL developer community\n",
    "- Articulates what makes one query better than another semantically equivalent query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 4:** Optimises SQL queries to map onto more efficient physical operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates indexes that prevent the materialisation of temporary tables.\n",
    "- Recognises queries that will have poor asymptotic complexity in the external memory model\n",
    "- Understands which logical operators can be rearranged in a query execution plan\n",
    "- Appreciates why SQL is only partly declarative in practice and how this influences query design\n",
    "- Connects the physical layout of tables and indexes to the implementation of physical query operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming application and business requirements into well-normalised data abstractions, documented with clear conceptual and relational schemata, and populating instances of those schemata from reliable data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 1:** Stores data in a set of tables that are compatible with data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selects appropriate data types for tables\n",
    "- Writes SQL code that implements a relational design\n",
    "- Loads data from .JSON and .CSV formats without truncation or other forms of data loss\n",
    "- Appends newly acquired data to pre-existing tables, modifying their structure as necessary\n",
    "- Documents the relationships between tables with syntactically and semantically correct entity-relationship diagrams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 2:** Constructs well-normalised conceptual and relational schemata that capture requirements without redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminates data anomalies with effective normalisation\n",
    "- Identifies dependencies among attributes and appropriate identifiers/keys for entity sets and relations\n",
    "- Justifies the quality of a schema through a theoretical lens\n",
    "- Maps requirements onto schemata and vice versa to ensure designs are minimal and complete\n",
    "- Internalises the merits of the relational data model even still today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 3:** Applies advanced ERD constructs and normalisation methods to produce more natural schemata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses inheritance and weak entity sets when they are more expressive than alternatives.\n",
    "- Assesses incongruity between conceptual and relational schemata.\n",
    "- Applies alternative normal forms when they better suit the application requirements.\n",
    "- Simplifies complicated relationships with powerful ERD constructs like ternary relationships, identifiers on relationships, and composite attributes\n",
    "- Systematically evaluates strengths and weaknesses of a schema using a consistent framework\n",
    "- Considers the impact of NULL values and inheritance on functional dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 4:** Designs industrial-strength databases that can be deployed in the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Designs for extensibility with an appreciation that data sources may change \n",
    "- Considers matters of data governance, ethics, and data privacy in deciding how to meet application requirements\n",
    "- Anticipates data access patterns and load in database design and carefully considers trade-offs like denormalisation\n",
    "- Develops conceptual schemata that are compatible with multiple logical database models\n",
    "- Avoids over-engineering designs in favour of simplicity and satisfying only those requirements already known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-end Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing compatible SQL and API code to interface and synchronise data between applications and relational databases, using appropriate access, data consistency, and concurrency controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 1:** Creates conditions to ensure relational databases exhibit ACID behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates transactions to batch queries into atomic units\n",
    "- Understands the consistency principle to ensure a database never enters an inconsistent state\n",
    "- Identifies whether a transaction execution schedule is non-serializable and the implications thereof\n",
    "- Can manually restore a database from a log file to ensure durability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 2:** Implements effective controls to ensure that a database can be used in a concurrent, multi-user environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identifies the privileges conferred to each user and the effects on other users of revoking those privileges \n",
    "- Creates views to regulate access to data and ensure better data privacy and data governance\n",
    "- Maximises database throughput by selecting justifiably minimal isolation levels for transactions based on transaction semantics\n",
    "- Understands the relationship between views and base tables and how DML privileges on views can affect underlying data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Level 3:** Develops robust data access tier API's to safely expose a relational database to other developers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implements stored procedures to improve efficiency of API execution\n",
    "- Preemptively designs API code to be robust to security threats like SQL injection attacks\n",
    "- Interfaces between alternative data layouts in application-layer data structures and RDBMS tables, e.g., with ORM's\n",
    "- Utilises best practices for connection objects, such as RAII to ensure that connections are closed\n",
    "- Provides mechanisms to push complex logic into the RDBMS and closer to the data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
